# Pepper - ParticlE Physics ProcEssoR
A python framework for analyzing NanoAODs. Easy to use and highly configurable.

Currently focusing on <img src="https://latex.codecogs.com/gif.latex?\mathrm{t\bar{t}}\rightarrow\mathrm{ll\nu\nu}" />.

## Installation
Requires Python3 and the Python packages `coffea`, `awkward`, `parsl`, `h5py`, `hdf5plugin` and `hjson`

```sh
python3 -m pip install --user --upgrade pip
python3 -m pip install --user coffea awkward parsl h5py hdf5plugin hjson
```

The features of the framework are implemented as a Python package, which is inside the `pepper` directory. To use it, you can add the path to where you downloaded the repository to the `PYTHONPATH` variable

```sh
git clone <repository url> pepper
export PYTHONPATH=`pwd`/pepper:$PYTHONPATH
```

## Installation through pip3
Alternatively, Pepper can be installed as a python package as follows:
```sh
git clone <repository url> pepper
cd pepper
python3 -m pip install . --user
```
Use the option `-e` to make the installed package editable.
Now, `pepper` can be imported as any other python package from any location.



## Usage
In Pepper an analysis is implemented as a Processor class. A short example of such a Processor can be found in [here](example/example_processor.py). A processor can be run using 'python3 -m pepper.runproc example_processor.py'

### Running on HTCondor
In order to run on HTCondor, one only has to specify the `--condor` parameter followed by the number of jobs desired. If an environment like anaconda or CMSSW is supposed to be used on the HTCondor node, one has to create a Shell script that can be sourced setting up the environment and provide its path via the `--condorinit` parameter or set the `PEPPER_CONDOR_ENV` environment variable locally to that path.

### Main scripts
The main directory of this repository contains several optional scripts to obtain inputs and plot outputs:

 - `calculate_DY_SFs.py`: Calculate scale factors for DY reweighting from the output of produce_DY_numbers.py
 - `compute_kinreco_hists.py`: Generate histograms needed for top-quark kinematic reconstruction
 - `compute_mc_lumifactors.py`: Compute <img align="top" src="https://latex.codecogs.com/gif.latex?{\cal L}\sigma/\sum w_{\mathrm{gen}}" />, the factors needed to scale MC to data
 - `compute_pileup_weights.py`: Compute scale factors for pileup reweighting
 - `delete_duplicate_outputs.py`: Check for duplication in the per event data produced by select_events.py, and move or delete any duplicates
 - `generate_btag_efficiencies.py`: Generate a ROOT file containing efficiency histograms needed for b-tagging scale factors
 - `merge_hists.py`: Caluclate weighted average of two SF histograms
 - `plot_control.py`: Create control plots from histogram output generated by `select_events.py`
 - `produce_DY_numbers.py`: Produce the numbers needed for DY SF calculation
 - `produce_met_xy_nums.py`: Convert MET-xy correction numbers from the C++ headers provided centrally to json files
 - `select_events.py`: Run the main analysis procedure, outputting histograms and per event data



## Configuration
Configuration is done via JSON files. Examples can be found in the `example` directory. Additional data needed for configuration, for example scale factors and cross sections, can be found in a separate data repository here https://gitlab.cern.ch/pepper/data
After downloading it, make sure to set the configuration variable "datadir" to the path where the data repository was downloaded.
For a detailed explanation on the configuration variables, see `config_ttbarll_documentation.md`.
